{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d76ef1d-4744-4c45-a82b-f467d5b9f141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CERerankingEvaluator\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers import evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b475f5-ee58-4ac1-aa12-16977ccda9b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = '../shopping_queries_dataset/'\n",
    "locale =\"us\"\n",
    "model_save_path = f\"./models_{locale}\"\n",
    "output_path = f\"{model_save_path}_training\"\n",
    "random_state = 42\n",
    "n_dev_queries = 200\n",
    "train_batch_size = 32\n",
    "train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79e3a06f-0c55-460a-a896-8eca6a27c315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "---------> cuda is activated <----------\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 0. Init variables \"\"\"\n",
    "col_query = \"query\"\n",
    "col_query_id = \"query_id\"\n",
    "col_product_id = \"product_id\" \n",
    "col_product_title = \"product_title\"\n",
    "col_product_locale = \"product_locale\"\n",
    "col_esci_label = \"esci_label\" \n",
    "col_small_version = \"small_version\"\n",
    "col_split = \"split\"\n",
    "col_gain = 'gain'\n",
    "col_features = [col_product_id]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "to_print = \"\".join(['-']*40)\n",
    "print(to_print)\n",
    "print(f\"---------> {device} is activated <----------\")\n",
    "print(to_print)\n",
    "esci_label2gain = {\n",
    "    'E' : 1.0,\n",
    "    'S' : 0.1,\n",
    "    'C' : 0.01,\n",
    "    'I' : 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72b73028-57b7-44fb-aeeb-446246f688fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" 1. Load data \"\"\"    \n",
    "df_examples = pd.read_parquet(os.path.join(dataset_path, 'shopping_queries_dataset_examples.parquet'))\n",
    "df_products = pd.read_parquet(os.path.join(dataset_path, 'shopping_queries_dataset_products.parquet'))\n",
    "df_examples_products = pd.merge(\n",
    "    df_examples,\n",
    "    df_products,\n",
    "    how='left',\n",
    "    left_on=[col_product_locale, col_product_id],\n",
    "    right_on=[col_product_locale, col_product_id]\n",
    ")\n",
    "df_examples_products = df_examples_products[df_examples_products[col_small_version] == 1]\n",
    "df_examples_products = df_examples_products[df_examples_products[col_product_locale] == locale]\n",
    "df_examples_products[col_gain] = df_examples_products[col_esci_label].apply(lambda esci_label: esci_label2gain[esci_label])\n",
    "\n",
    "df_train = df_examples_products[[col_query_id, col_query, *col_features, col_gain]][df_examples_products[col_split] == \"train\"]\n",
    "list_query_id = df_train[col_query_id].unique()\n",
    "dev_size = n_dev_queries / len(list_query_id)\n",
    "list_query_id_train, list_query_id_dev = train_test_split(list_query_id, test_size=dev_size, random_state=random_state)\n",
    "\n",
    "df_train = df_examples_products[df_examples_products[col_query_id].isin(list_query_id_train)]\n",
    "df_dev = df_examples_products[df_examples_products[col_query_id].isin(list_query_id_dev)]\n",
    "df_test = df_examples_products[df_examples_products[col_split] == \"test\"]\n",
    "\n",
    "# This part of the code is for indexing and it is assumed the only input feature is product_title.\n",
    "# Otherwise it shoudl be updated asccordingly\n",
    "id_features_product_test = df_test[[col_product_id, col_product_title]].drop_duplicates(subset=col_product_title)\n",
    "\n",
    "features_product_test = id_features_product_test[col_product_title].to_list()\n",
    "id_product_test = id_features_product_test[col_product_id].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cd697b-2ee6-4bdd-a383-594566d21174",
   "metadata": {},
   "source": [
    "# Inferencing Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40f38caf-a7ac-4cb7-b857-4b42d1ebcc2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieval_inference(model_path, text=None, batch_scoring=False, query_result_pair=None, batch_size=256):\n",
    "    \"\"\" Embeddings for the trained bi-encoder models \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = AutoModel.from_pretrained(model_path).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    # CLS Pooling - Take output from first token\n",
    "    def cls_pooling(model_output):\n",
    "        return model_output.last_hidden_state[:,0]\n",
    "    # Encode text\n",
    "    def encode(texts):\n",
    "        # Tokenize sentences\n",
    "        encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        # Compute token embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded_input, return_dict=True)\n",
    "        # Perform pooling\n",
    "        embeddings = cls_pooling(model_output)\n",
    "        return embeddings\n",
    "    model.eval()\n",
    "    if not batch_scoring:\n",
    "        return encode(text)\n",
    "    features_query, features_product = query_result_pair\n",
    "    n_examples = len(features_query)\n",
    "    scores = np.zeros(n_examples)\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, n_examples, batch_size)):\n",
    "            j = min(i + batch_size, n_examples)\n",
    "            features_query_ = features_query[i:j]\n",
    "            features_product_ = features_product[i:j]\n",
    "            query_emb = encode(features_query_)\n",
    "            product_emb = encode(features_product_)\n",
    "            scores[i:j] = torch.diagonal(torch.mm(query_emb, product_emb.transpose(0, 1)).to('cpu'))\n",
    "            i = j\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4605bd7-f2d1-4f57-b9ba-f198898faab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reranking_inference(model_path, features_query, features_product, batch_size=256):\n",
    "    \"\"\" Scoring for the trained cross-encoder models \"\"\"\n",
    "    n_examples = len(features_query)\n",
    "    scores = np.zeros(n_examples)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, n_examples, batch_size)):\n",
    "            j = min(i + batch_size, n_examples)\n",
    "            features_query_ = features_query[i:j]\n",
    "            features_product_ = features_product[i:j]\n",
    "            features = tokenizer(features_query_, features_product_, \n",
    "                                 padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "            scores[i:j] = np.squeeze(model(**features).logits.cpu().detach().numpy())\n",
    "            i = j\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d94eb3f9-d975-4783-b9d4-40e6f90ecf07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 710/710 [09:46<00:00,  1.21it/s]\n",
      "/tmp/ipykernel_2600/2815086895.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.loc[:, f\"retrieval_{retrieval_model_path.split('/')[-1]}\"] = scores.copy()\n",
      "/home/dell/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 710/710 [09:46<00:00,  1.21it/s]\n",
      "/tmp/ipykernel_2600/2815086895.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.loc[:, f\"retrieval_{retrieval_model_path.split('/')[-1]}\"] = scores.copy()\n",
      "/home/dell/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "100%|██████████| 710/710 [03:03<00:00,  3.88it/s]\n",
      "/tmp/ipykernel_2600/2815086895.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.loc[:, f\"ranking_{ranking_model_path.split('/')[-1]}\"] = scores.copy()\n"
     ]
    }
   ],
   "source": [
    "features_query = df_test[col_query]\n",
    "features_products = df_test[col_product_title]\n",
    "\n",
    "retrieval_model_paths = [\n",
    "    'sentence-transformers/multi-qa-mpnet-base-dot-v1', # specific for semantic search\n",
    "    'sentence-transformers/all-mpnet-base-v2' # general purpose model\n",
    "]\n",
    "ranking_model_paths = [\n",
    "    'cross-encoder/ms-marco-MiniLM-L-12-v2',\n",
    "    # './models_us_training_reranking_cross-encoder/stsb-roberta-large'\n",
    "]\n",
    "\n",
    "for retrieval_model_path in retrieval_model_paths:\n",
    "    scores = retrieval_inference(retrieval_model_path, batch_scoring=True, \n",
    "                                 query_result_pair=(features_query.to_list(), \n",
    "                                                    features_products.to_list()))\n",
    "    df_test.loc[:, f\"retrieval_{retrieval_model_path.split('/')[-1]}\"] = scores.copy()\n",
    "    \n",
    "for ranking_model_path in ranking_model_paths:     \n",
    "    scores = reranking_inference(ranking_model_path, \n",
    "                                 features_query.to_list(), \n",
    "                                 features_products.to_list())\n",
    "    df_test.loc[:, f\"ranking_{ranking_model_path.split('/')[-1]}\"] = scores.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2842e952-88d6-4d47-bd92-33bed021f979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test.to_csv(\"./scores_from_pretrained_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03ce03a9-d6bc-4995-9bf2-114d5767b744",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrieval_multi-qa-mpnet-base-dot-v1</th>\n",
       "      <th>retrieval_all-mpnet-base-v2</th>\n",
       "      <th>ranking_ms-marco-MiniLM-L-12-v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>19.696350</td>\n",
       "      <td>2.835467</td>\n",
       "      <td>-11.331335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>22.133604</td>\n",
       "      <td>3.423887</td>\n",
       "      <td>-11.169686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>21.063263</td>\n",
       "      <td>3.756823</td>\n",
       "      <td>-10.976269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>21.452841</td>\n",
       "      <td>4.178871</td>\n",
       "      <td>-9.424541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>21.738901</td>\n",
       "      <td>4.446245</td>\n",
       "      <td>-9.285576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614589</th>\n",
       "      <td>12.671896</td>\n",
       "      <td>1.713727</td>\n",
       "      <td>-11.321844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614590</th>\n",
       "      <td>9.298196</td>\n",
       "      <td>1.120765</td>\n",
       "      <td>-11.325283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614591</th>\n",
       "      <td>10.096718</td>\n",
       "      <td>1.734619</td>\n",
       "      <td>-11.307865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614592</th>\n",
       "      <td>12.950536</td>\n",
       "      <td>1.788636</td>\n",
       "      <td>-11.316772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614593</th>\n",
       "      <td>15.037594</td>\n",
       "      <td>1.961052</td>\n",
       "      <td>-11.327539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181701 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         retrieval_multi-qa-mpnet-base-dot-v1  retrieval_all-mpnet-base-v2  \\\n",
       "32                                  19.696350                     2.835467   \n",
       "33                                  22.133604                     3.423887   \n",
       "34                                  21.063263                     3.756823   \n",
       "35                                  21.452841                     4.178871   \n",
       "36                                  21.738901                     4.446245   \n",
       "...                                       ...                          ...   \n",
       "2614589                             12.671896                     1.713727   \n",
       "2614590                              9.298196                     1.120765   \n",
       "2614591                             10.096718                     1.734619   \n",
       "2614592                             12.950536                     1.788636   \n",
       "2614593                             15.037594                     1.961052   \n",
       "\n",
       "         ranking_ms-marco-MiniLM-L-12-v2  \n",
       "32                            -11.331335  \n",
       "33                            -11.169686  \n",
       "34                            -10.976269  \n",
       "35                             -9.424541  \n",
       "36                             -9.285576  \n",
       "...                                  ...  \n",
       "2614589                       -11.321844  \n",
       "2614590                       -11.325283  \n",
       "2614591                       -11.307865  \n",
       "2614592                       -11.316772  \n",
       "2614593                       -11.327539  \n",
       "\n",
       "[181701 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['retrieval_multi-qa-mpnet-base-dot-v1',\n",
    "         'retrieval_all-mpnet-base-v2',\n",
    "         'ranking_ms-marco-MiniLM-L-12-v2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695b782b-6ae8-442a-9da7-a4dd4e9a007f",
   "metadata": {},
   "source": [
    "## Evaluating Results and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33a8d526-5ea7-4507-9cac-7819b3be11b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> MRR for trained models: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2600/3091718691.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'rank'] = df.groupby('query_id')[col].rank(method='min', ascending=False).values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieval_multi-qa-mpnet-base-dot-v1': OrderedDict([('MRR', 0.7767),\n",
      "                                                      ('Hits@1', 0.6556),\n",
      "                                                      ('Hits@5', 0.932),\n",
      "                                                      ('Hits@10', 0.9792)])}\n",
      "{'retrieval_all-mpnet-base-v2': OrderedDict([('MRR', 0.7648),\n",
      "                                             ('Hits@1', 0.6426),\n",
      "                                             ('Hits@5', 0.9252),\n",
      "                                             ('Hits@10', 0.979)])}\n",
      "{'ranking_ms-marco-MiniLM-L-12-v2': OrderedDict([('MRR', 0.7898),\n",
      "                                                 ('Hits@1', 0.6738),\n",
      "                                                 ('Hits@5', 0.9358),\n",
      "                                                 ('Hits@10', 0.9774)])}\n"
     ]
    }
   ],
   "source": [
    "from ampligraph.evaluation.metrics import mrr_score, hits_at_n_score\n",
    "from collections import OrderedDict\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def calculate_metrics(df, col, hit_at_n=[1, 5, 10], pure_python=False):\n",
    "    \"\"\" Calculatye Metrics: MRR and Hits@n\n",
    "    It uses Ampligraph based on Tensorflow: https://docs.ampligraph.org/en/latest/index.html\n",
    "    If you prefer to do calculation based on pure Python, set pure_python=True\n",
    "    \"\"\"\n",
    "    result = OrderedDict()\n",
    "    df.loc[:, 'rank'] = df.groupby('query_id')[col].rank(method='min', ascending=False).values\n",
    "    first_hit_rank_position = df.groupby('query_id')[['gain', 'rank']] \\\n",
    "        .apply(lambda x: x[x.gain == 1.0]['rank'].min()).values\n",
    "    \n",
    "    first_hit_rank_position = np.nan_to_num(first_hit_rank_position, nan=1000)\n",
    "    \n",
    "    if not pure_python:\n",
    "        result[\"MRR\"] = mrr_score(first_hit_rank_position).round(4)\n",
    "        for h in hit_at_n:\n",
    "            result[f\"Hits@{h}\"] = hits_at_n_score(first_hit_rank_position, n=h).round(4)\n",
    "        \n",
    "    else:\n",
    "        n_queries = first_hit_rank_position.shape[0]\n",
    "        result[\"MRR\"] = np.divide(np.divide(1, first_hit_rank_position).sum(), \n",
    "                                  n_queries).round(4)\n",
    "        for h in hit_at_n:\n",
    "            result[f\"Hits@{h}\"] = np.divide((first_hit_rank_position <= h).sum(),\n",
    "                                            n_queries).round(4)\n",
    "    return result\n",
    "\n",
    "target_cols = ['retrieval_multi-qa-mpnet-base-dot-v1',\n",
    "               'retrieval_all-mpnet-base-v2',\n",
    "               'ranking_ms-marco-MiniLM-L-12-v2']\n",
    "metrics = OrderedDict()\n",
    "print(f\"--> MRR for trained models: \\n\")\n",
    "for col in target_cols:    \n",
    "    pprint({col: calculate_metrics(df_test, col)})\n",
    "    metrics[col] = calculate_metrics(df_test, col).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab819b-52e5-4bf4-9c5b-4f2d311cc5a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Indexing with FAISS \n",
    "\n",
    "Note: Just indexing test set to save time and for evaluation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23da8c52-2ce0-494b-a9db-debd5169b281",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/639 [00:00<?, ?it/s]/home/dell/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 639/639 [18:47<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "model_path = 'sentence-transformers/multi-qa-mpnet-base-dot-v1'\n",
    "\n",
    "def indexing_faiss(list_to_index, model_path, index_file_name, batch_size=256):\n",
    "    embedding_size = 768\n",
    "    n_examples = len(list_to_index)\n",
    "    index = faiss.IndexIDMap(faiss.IndexFlatIP(embedding_size))\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, n_examples, batch_size)):\n",
    "            j = min(i + batch_size, n_examples)\n",
    "            list_to_index_ = list_to_index[i:j]\n",
    "            index.add_with_ids(\n",
    "                retrieval_inference(model_path=model_path, text=list_to_index_) \\\n",
    "                    .to('cpu').numpy().astype('float32'), \n",
    "                np.array(range(i, j))\n",
    "            )\n",
    "    assert index.ntotal == n_examples, \"Not all the inputs are indexed\"\n",
    "    faiss.write_index(index, index_file_name)\n",
    "\n",
    "def global_index_file_name(model_path, locale):\n",
    "    if locale: return f\"./{locale}_{model_path.split('/')[-1]}.index\"\n",
    "    return f\"./{model_path.split('/')[-1]}.index\"\n",
    "\n",
    "index_file_name = f\"./pretrained_multi-qa-mpnet-base-dot-v1.index\"\n",
    "if not os.path.isfile(index_file_name):\n",
    "    indexing_faiss(list_to_index=features_product_test, \n",
    "                   model_path=model_path,\n",
    "                   index_file_name=index_file_name, \n",
    "                   batch_size=256\n",
    "                  )\n",
    "else:\n",
    "    print(f\"The index file exist {index_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aba013-2e9e-4c97-814f-422b5e438d53",
   "metadata": {},
   "source": [
    "## Inference Retrieval-Indexing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfcc3bfe-fae7-4998-b67d-5e7acfdd6871",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results in Total Time: 1.0279555320739746\n",
      "{'query': '!qscreen fence without holes',\n",
      " 'retrieval results': [{'Product ID': 'B01N1P9MYW', 'Product Title': 'Fences'},\n",
      "                       {'Product ID': 'B07R6P8TK8',\n",
      "                        'Product Title': \"Amgo 4' x 50' Black Fence Privacy \"\n",
      "                                         'Screen Windscreen,with Bindings & '\n",
      "                                         'Grommets, Heavy Duty for Commercial '\n",
      "                                         'and Residential, 90% Blockage, Cable '\n",
      "                                         'Zip Ties Included, (Available for '\n",
      "                                         'Custom Sizes)'},\n",
      "                       {'Product ID': 'B07XCGC4ZM',\n",
      "                        'Product Title': 'Good Fences'},\n",
      "                       {'Product ID': 'B00ZBE9IMQ',\n",
      "                        'Product Title': 'The Fence'},\n",
      "                       {'Product ID': 'B07R3TNQDM',\n",
      "                        'Product Title': \"Amgo 6' x 50' Black Fence Privacy \"\n",
      "                                         'Screen Windscreen,with Bindings & '\n",
      "                                         'Grommets, Heavy Duty for Commercial '\n",
      "                                         'and Residential, 90% Blockage, Cable '\n",
      "                                         'Zip Ties Included, (Available for '\n",
      "                                         'Custom Sizes)'}]}\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "from pprint import pprint\n",
    "\n",
    "model_path = 'sentence-transformers/multi-qa-mpnet-base-dot-v1'\n",
    "\n",
    "def fetch_id_product(indices):\n",
    "    return [{\"Product ID\": id_product_test[i], \"Product Title\": features_product_test[i]} for i in indices]\n",
    "\n",
    "def retriev(query, top_k=5, locale=\"us\", model_path=model_path):\n",
    "    index = faiss.read_index(f\"pretrained_{model_path.split('/')[-1]}.index\")\n",
    "    tick = time.time()\n",
    "    query_vector = retrieval_inference(model_path, query).to('cpu').numpy().astype('float32')\n",
    "    top_k = index.search(query_vector, top_k)\n",
    "    print(f\"Results in Total Time: {time.time() - tick}\")\n",
    "    top_k_ids = top_k[1].tolist()[0]\n",
    "    return fetch_id_product(top_k_ids)\n",
    "\n",
    "query = df_test[col_query].iloc[0]\n",
    "pprint({\"query\": query, \"retrieval results\": retriev(query)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804c4eda-165b-432f-9be1-8dc15e2629bc",
   "metadata": {},
   "source": [
    "## End-to-End System Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd76de5e-1bb1-4a65-9488-3faf431de981",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/dell/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 10/10 [02:41<00:00, 16.10s/it]\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "from pprint import pprint\n",
    "\n",
    "# Selected Retrieval Model\n",
    "model_path = 'sentence-transformers/multi-qa-mpnet-base-dot-v1'\n",
    "n_batches=10\n",
    "batch_size=10\n",
    "top_k=30\n",
    "\n",
    "def fetch_id_product(row, indices):\n",
    "    return [{col_query_id: row[col_query_id],\n",
    "             col_query: row[col_query],\n",
    "             col_product_id: id_product_test[i], \n",
    "             col_product_title: features_product_test[i]} for i in indices]\n",
    "\n",
    "def retriev(row, top_k=5, locale=\"us\", model_path=model_path):\n",
    "    index = faiss.read_index(f\"pretrained_{model_path.split('/')[-1]}.index\")\n",
    "    query_vector = retrieval_inference(model_path, row[col_query]).to('cpu').numpy().astype('float32')\n",
    "    top_k = index.search(query_vector, top_k)\n",
    "    top_k_ids = top_k[1].tolist()[0]\n",
    "    return fetch_id_product(row, top_k_ids)\n",
    "\n",
    "def sampling_retrieval(model_path, df_queries, n_batches=n_batches, batch_size=batch_size, top_k=top_k):\n",
    "    result = []\n",
    "    for i in tqdm(range(n_batches)):\n",
    "        features_queries = df_queries.sample(n=batch_size) # default replacement is False\n",
    "        for (_, row) in features_queries.iterrows():\n",
    "            result.append(retriev(row, top_k=top_k, locale=\"us\", model_path=model_path))       \n",
    "    return result\n",
    "\n",
    "df_queries = df_test[[col_query_id, col_query, col_gain]].drop_duplicates()\n",
    "result = sampling_retrieval(model_path, df_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3498aaf5-ee0d-45e2-b844-f9b47f89b94e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  5.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.67it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.81it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.78it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.16it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.66it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.43it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.42it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.52it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.66it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.28it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.87it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.19it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.42it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.89it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.69it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.33it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.81it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.57it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.76it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.34it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  6.10it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.09it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  5.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "def flatten_chain(matrix):\n",
    "    return list(chain.from_iterable(matrix))\n",
    "\n",
    "ranking_model_path = 'cross-encoder/ms-marco-MiniLM-L-12-v2'\n",
    "col = 'ranking_ms-marco-MiniLM-L-12-v2'\n",
    "sample_size = 20 # less than 100\n",
    "sample_result = []\n",
    "n_iterations = 30\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    df_ = pd.DataFrame(flatten_chain(random.sample(result, sample_size)))\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        scores = reranking_inference(ranking_model_path, \n",
    "                                     df_[col_query].to_list(), \n",
    "                                     df_[col_product_title].to_list())\n",
    "    score_col = f\"ranking_{ranking_model_path.split('/')[-1]}\"\n",
    "    df_.loc[:, score_col] = scores.copy()\n",
    "    df_.loc[:, \"rank\"] = df_.groupby(col_query_id)[score_col].rank(method='min', ascending=False).values\n",
    "    df_ = df_[df_['rank'] <= 10]\n",
    "    df_rank = df_test[df_test[col_query_id].isin(df_[col_query_id].unique())][[col_query_id, col_product_id, col_gain]].merge(\n",
    "        df_,\n",
    "        how='left',\n",
    "        on=[col_query_id, col_product_id]\n",
    "    )\n",
    "    df_rank.loc[:, 'rank'] = df_rank.groupby('query_id')[col]. \\\n",
    "    rank(method='min', ascending=False).values\n",
    "    df_rank['ranking_ms-marco-MiniLM-L-12-v2'] = df_rank['ranking_ms-marco-MiniLM-L-12-v2'].fillna(0)\n",
    "    sample_result.append(calculate_metrics(df_rank, col).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3069f87-82f8-4a88-888e-c9ff119dfaed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MRR</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.896953</td>\n",
       "      <td>0.053950</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>0.865875</td>\n",
       "      <td>0.89585</td>\n",
       "      <td>0.927325</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hits@1</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.821667</td>\n",
       "      <td>0.092553</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hits@5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.988333</td>\n",
       "      <td>0.021509</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hits@10</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.988333</td>\n",
       "      <td>0.021509</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count      mean       std     min       25%      50%       75%  max\n",
       "MRR       30.0  0.896953  0.053950  0.7542  0.865875  0.89585  0.927325  1.0\n",
       "Hits@1    30.0  0.821667  0.092553  0.5500  0.800000  0.80000  0.887500  1.0\n",
       "Hits@5    30.0  0.988333  0.021509  0.9500  1.000000  1.00000  1.000000  1.0\n",
       "Hits@10   30.0  0.988333  0.021509  0.9500  1.000000  1.00000  1.000000  1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sample_result).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1e6b3-f161-4bec-a25f-180283d0fcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(root) Python *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
